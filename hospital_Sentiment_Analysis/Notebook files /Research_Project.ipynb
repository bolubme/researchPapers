{"cells":[{"cell_type":"markdown","metadata":{"id":"h0eTYuMEoj7C"},"source":["### **Topic : Service quality of hospitals in Nigeria using Geo-semantic analysis of citizn's social media post**"]},{"cell_type":"markdown","metadata":{"id":"Ji8UEayMx7rA"},"source":["### **ANALYSIS OF TWITTER POST**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F6pGonNnBgMS"},"outputs":[],"source":["!pip install snscrape\n","!pip install pandas                                \n","!pip install textblob\n","!pip install emoji"]},{"cell_type":"markdown","metadata":{"id":"U99DUKztzYgK"},"source":["### **Used Python Libraries**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"X1z2j3v3JQ9z"},"outputs":[],"source":["# import necessary libraries\n","import re\n","import nltk\n","import gensim\n","import pandas as pd\n","\n","from nltk.stem import WordNetLemmatizer\n","import matplotlib.pyplot as plt\n","nltk.download('wordnet')"]},{"cell_type":"markdown","metadata":{"id":"vPZ8nwBoO2p2"},"source":["### Step 1: Collect **Data**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2936,"status":"error","timestamp":1683672430182,"user":{"displayName":"Boluwatife Morolari","userId":"04350220273514722696"},"user_tz":-60},"id":"Ch58nDgJzrl6","outputId":"6dc89970-1a84-44ed-e919-8aebdbbd55f1"},"outputs":[{"ename":"KeyboardInterrupt","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-3f8510a9b9e8>\u001b[0m in \u001b[0;36m<cell line: 43>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mhospital\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhospital_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'(\"{hospital}\" OR \"{hospital_dict[hospital]}\") near:\"Nigeria\" lang:en'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtweet\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msntwitter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTwitterSearchScraper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_items\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mtweet_limit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/snscrape/modules/twitter.py\u001b[0m in \u001b[0;36mget_items\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1659\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cursor'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1660\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1661\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iter_api_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'https://api.twitter.com/2/search/adaptive.json'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_TwitterAPIType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mV2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpaginationParams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcursor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cursor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1662\u001b[0m                         \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_v2_timeline_instructions_to_tweets_or_users\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1663\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/snscrape/modules/twitter.py\u001b[0m in \u001b[0;36m_iter_api_data\u001b[0;34m(self, endpoint, apiType, params, paginationParams, cursor, direction)\u001b[0m\n\u001b[1;32m    759\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m                         \u001b[0m_logger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Retrieving scroll page {cursor}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 761\u001b[0;31m                         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_api_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapiType\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreqParams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    762\u001b[0m                         \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/snscrape/modules/twitter.py\u001b[0m in \u001b[0;36m_get_api_data\u001b[0;34m(self, endpoint, apiType, params)\u001b[0m\n\u001b[1;32m    725\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mapiType\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0m_TwitterAPIType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGRAPHQL\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m                         \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseparators\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m':'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquote_via\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquote\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m                 \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apiHeaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponseOkCallback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_api_response\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m                         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/snscrape/base.py\u001b[0m in \u001b[0;36m_get\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'GET'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_post\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/snscrape/base.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, method, url, params, data, headers, timeout, responseOkCallback, allowRedirects, proxies)\u001b[0m\n\u001b[1;32m    220\u001b[0m                                                 \u001b[0m_logger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'... ... with response headers: {redirect.headers!r}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m                                 \u001b[0;32mif\u001b[0m \u001b[0mresponseOkCallback\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m                                         \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponseOkCallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m                                         \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m                                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/snscrape/modules/twitter.py\u001b[0m in \u001b[0;36m_check_api_response\u001b[0;34m(self, r)\u001b[0m\n\u001b[1;32m    713\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m403\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m404\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m429\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    714\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unset_guest_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 715\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_guest_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    716\u001b[0m                         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'blocked ({r.status_code})'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    717\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'content-type'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'application/json;charset=utf-8'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/snscrape/modules/twitter.py\u001b[0m in \u001b[0;36m_ensure_guest_token\u001b[0;34m(self, url)\u001b[0m\n\u001b[1;32m    685\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_guestTokenManager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m                         \u001b[0m_logger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Retrieving guest token'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 687\u001b[0;31m                         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_baseUrl\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0murl\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'User-Agent'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_userAgent\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponseOkCallback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_guest_token_response\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    688\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmatch\u001b[0m \u001b[0;34m:=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'document\\.cookie = decodeURIComponent\\(\"gt=(\\d+); Max-Age=10800; Domain=\\.twitter\\.com; Path=/; Secure\"\\);'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m                                 \u001b[0m_logger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Found guest token in HTML'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/snscrape/base.py\u001b[0m in \u001b[0;36m_get\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'GET'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_post\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/snscrape/base.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, method, url, params, data, headers, timeout, responseOkCallback, allowRedirects, proxies)\u001b[0m\n\u001b[1;32m    201\u001b[0m                                 \u001b[0m_logger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'... with environmentSettings: {environmentSettings!r}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m                         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m                                 \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_redirects\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mallowRedirects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0menvironmentSettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m                         \u001b[0;32mexcept\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRequestException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m                                 \u001b[0;32mif\u001b[0m \u001b[0mattempt\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retries\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    643\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 645\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    438\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mchunked\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m                 resp = conn.urlopen(\n\u001b[0m\u001b[1;32m    441\u001b[0m                     \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m                     \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m             \u001b[0;31m# Make the request on the httplib connection object.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m             httplib_response = self._make_request(\n\u001b[0m\u001b[1;32m    704\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    447\u001b[0m                     \u001b[0;31m# Python 3 (including for exceptions like SystemExit).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m                     \u001b[0;31m# Otherwise it looks like a bug in the code.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m                     \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSocketError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mread_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    442\u001b[0m                 \u001b[0;31m# Python 3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 444\u001b[0;31m                     \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    445\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m                     \u001b[0;31m# Remove the TypeError from the exception chain in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1373\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1374\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1375\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1376\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1377\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0;31m# read until we get a non-100 response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"status line\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 705\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    706\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1272\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1273\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1274\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1275\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1276\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1129\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1130\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["import snscrape.modules.twitter as sntwitter\n","import pandas as pd\n","\n","# Define the hospital names and their abbreviations to use for scraping\n","hospital_dict = {'Lagos University Teaching Hospital': 'LUTH', 'National Hospital Abuja': 'NHA',\n","                  'University College Hospital Ibadan': 'UCH', 'St. Nicholas Hospital Lagos': 'SNHL',\n","                  'Reddington Hospital Lagos': 'RHL', 'Eko Hospital Lagos': 'EHL',\n","                  'First Consultant Medical Centre Lagos': 'FCMC', 'Isolo General Hospital Lagos': 'IGHL',\n","                  'Lagoon Hospitals Lagos': 'LHL', 'Abuja Clinics': 'AC', 'Cedarcrest Hospitals Abuja': 'CHA',\n","                  'Asokoro District Hospital Abuja': 'ADHA', 'Garki Hospital Abuja': 'GHA',\n","                  'Wuse General Hospital Abuja': 'WGHA', 'Nizamiye Hospital Abuja': 'NHA',\n","                  'University of Abuja Teaching Hospital': 'UATH', 'University of Nigeria Teaching Hospital': 'UNTH',\n","                  'University of Benin Teaching Hospital': 'UBTH',\n","                  'University of Port Harcourt Teaching Hospital': 'UPTH',\n","                  'University of Ilorin Teaching Hospital': 'UITH',\n","                  'Aminu Kano Teaching Hospital': 'AKTH', 'University of Maiduguri Teaching Hospital': 'UMTH',\n","                  'Federal Medical Centre Abeokuta': 'FMCA', 'Federal Medical Centre Abuja': 'FMCAb',\n","                  'Federal Medical Centre Asaba': 'FMCAb', 'Federal Medical Centre Azare': 'FMCAz',\n","                  'Federal Medical Centre Bida': 'FMCB', 'Federal Medical Centre Birnin-Kebbi': 'FMCBK',\n","                  'Federal Medical Centre Ebute-Metta': 'FMCE', 'Federal Medical Centre Gombe': 'FMCG',\n","                  'Federal Medical Centre Gusau': 'FMCG', 'Federal Medical Centre Ido-Ekiti': 'FMCIE',\n","                  'Federal Medical Centre Jalingo': 'FMCJ', 'Federal Medical Centre Katsina': 'FMCK',\n","                  'Federal Medical Centre Keffi': 'FMCK', 'Federal Medical Centre Lafia': 'FMCL',\n","                  'Federal Medical Centre Makurdi': 'FMCM', 'Federal Medical Centre Nguru': 'FMCN',\n","                  'Federal Medical Centre Owerri': 'FMCO', 'Federal Medical Centre Owo': 'FMCO',\n","                  'Federal Medical Centre Oyo': 'FMCO', 'Federal Medical Centre Umuahia': 'FMCU',\n","                  'Federal Medical Centre Umuahia': 'FMCU', 'Federal Medical Centre Yenagoa': 'FMCY',\n","                  'Federal Medical Centre Yola': 'FMCY', 'Gbagada General Hospital Lagos': 'GGHL',\n","                  'General Hospital Lagos': 'GHL', 'Igbobi Orthopaedic Hospital Lagos': 'IOHL',\n","                  'Ikeja General Hospital Lagos': 'IGHL', 'Imo State University Teaching Hospital Orlu': 'IMSU',\n","                  'Irrua Specialist Teaching Hospital': 'ISTH', 'Island Maternity Hospital Lagos': 'IMHL',\n","                  'Kaduna State University Teaching Hospital': 'KASUTH', 'Lagos Island General Hospital': 'LIGHL',\n","                  'Maryam Abacha American University Teaching Hospital': 'MAAUT', 'Military Hospital Lagos': 'MHL',\n","                  'National Orthopaedic Hospital Lagos': 'NOHIL' }\n","\n","# Define the tweet limit for scraping\n","tweet_limit = 30000\n","\n","# Create an empty list to store the scraped tweets\n","tweets_list = []\n","\n","# Loop through the hospital names and use snscrape to scrape tweets for each hospital\n","for hospital in hospital_dict.keys():\n","    query = f'(\"{hospital}\" OR \"{hospital_dict[hospital]}\") near:\"Nigeria\" lang:en'\n","    for i, tweet in enumerate(sntwitter.TwitterSearchScraper(query).get_items()):\n","        if i >= tweet_limit:\n","            break\n","        tweets_list.append([tweet.date, tweet.content, location])\n","\n","# Convert the list of scraped tweets to a pandas dataframe\n","tweets_df = pd.DataFrame(tweets_list, columns=['Datetime', 'Text', 'Location'])\n","\n","# Save the dataframe as a csv file\n","tweets_df.to_csv('hospital_train.csv', index=False)\n"]},{"cell_type":"markdown","metadata":{"id":"9dhSFnOo9sDQ"},"source":["### **Load Data**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FPljzhML9w0b"},"outputs":[],"source":["# Load the CSV file into a Pandas DataFrame\n","tweets_df = pd.read_csv('/content/drive/MyDrive/tweets.csv', lineterminator='\\n')\n","\n","# Print the first few rows of the DataFrame\n","# print(tweets.head())\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":363},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1685039504078,"user":{"displayName":"Boluwatife Morolari","userId":"04350220273514722696"},"user_tz":-60},"id":"ZWCntU9VJcK-","outputId":"3c550e3e-35b1-473a-e7e6-68cbd8aedf76"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-7ab5a105-677a-411b-8614-4d5929cb2bbd\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Datetime</th>\n","      <th>Text</th>\n","      <th>Location</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2023-04-12 13:15:21+00:00</td>\n","      <td>LUTH accident and emergency ward is noting too...</td>\n","      <td>8.6753° N, 9.0810° E, 200km</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2023-04-12 13:15:21+00:00</td>\n","      <td>I was at LUTH emergency one time.There were do...</td>\n","      <td>8.6753° N, 9.0810° E, 200km</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2023-04-07 10:32:19+00:00</td>\n","      <td>@MrLamiofficial @shilepoppa I met a man that c...</td>\n","      <td>8.6753° N, 9.0810° E, 200km</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2023-04-07 10:10:28+00:00</td>\n","      <td>If the dilapidated system is receiving some re...</td>\n","      <td>8.6753° N, 9.0810° E, 200km</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2023-04-07 09:50:33+00:00</td>\n","      <td>@AdesojiMinkail There is nothing real about th...</td>\n","      <td>8.6753° N, 9.0810° E, 200km</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>2023-04-06 10:29:35+00:00</td>\n","      <td>@RonforteTowers @DeeOneAyekooto Yes they did i...</td>\n","      <td>8.6753° N, 9.0810° E, 200km</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>2023-04-06 09:09:50+00:00</td>\n","      <td>@osita_chidoka @GeoffreyOnyeama @Reuters @BBCN...</td>\n","      <td>8.6753° N, 9.0810° E, 200km</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>2023-04-06 08:50:28+00:00</td>\n","      <td>They imprison you in government hospitals if y...</td>\n","      <td>8.6753° N, 9.0810° E, 200km</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>2023-04-03 12:11:40+00:00</td>\n","      <td>Luth General Surgery Monday morning reviews. P...</td>\n","      <td>8.6753° N, 9.0810° E, 200km</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>2023-04-03 07:26:56+00:00</td>\n","      <td>@jerzyakor I have not experienced JUTH but LUT...</td>\n","      <td>8.6753° N, 9.0810° E, 200km</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7ab5a105-677a-411b-8614-4d5929cb2bbd')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-7ab5a105-677a-411b-8614-4d5929cb2bbd button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-7ab5a105-677a-411b-8614-4d5929cb2bbd');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                    Datetime  \\\n","0  2023-04-12 13:15:21+00:00   \n","1  2023-04-12 13:15:21+00:00   \n","2  2023-04-07 10:32:19+00:00   \n","3  2023-04-07 10:10:28+00:00   \n","4  2023-04-07 09:50:33+00:00   \n","5  2023-04-06 10:29:35+00:00   \n","6  2023-04-06 09:09:50+00:00   \n","7  2023-04-06 08:50:28+00:00   \n","8  2023-04-03 12:11:40+00:00   \n","9  2023-04-03 07:26:56+00:00   \n","\n","                                                Text  \\\n","0  LUTH accident and emergency ward is noting too...   \n","1  I was at LUTH emergency one time.There were do...   \n","2  @MrLamiofficial @shilepoppa I met a man that c...   \n","3  If the dilapidated system is receiving some re...   \n","4  @AdesojiMinkail There is nothing real about th...   \n","5  @RonforteTowers @DeeOneAyekooto Yes they did i...   \n","6  @osita_chidoka @GeoffreyOnyeama @Reuters @BBCN...   \n","7  They imprison you in government hospitals if y...   \n","8  Luth General Surgery Monday morning reviews. P...   \n","9  @jerzyakor I have not experienced JUTH but LUT...   \n","\n","                     Location   \n","0  8.6753° N, 9.0810° E, 200km  \n","1  8.6753° N, 9.0810° E, 200km  \n","2  8.6753° N, 9.0810° E, 200km  \n","3  8.6753° N, 9.0810° E, 200km  \n","4  8.6753° N, 9.0810° E, 200km  \n","5  8.6753° N, 9.0810° E, 200km  \n","6  8.6753° N, 9.0810° E, 200km  \n","7  8.6753° N, 9.0810° E, 200km  \n","8  8.6753° N, 9.0810° E, 200km  \n","9  8.6753° N, 9.0810° E, 200km  "]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["tweets_df.head(10)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":22,"status":"ok","timestamp":1683940642121,"user":{"displayName":"Boluwatife Morolari","userId":"04350220273514722696"},"user_tz":-60},"id":"g7w4rWiHGy1V","outputId":"12160cff-19b8-47a5-afbc-ef32809b95ad"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-81d231ad-fe69-4257-8ec8-600b5666d3e6\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Datetime</th>\n","      <th>tweet</th>\n","      <th>Location</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2023-04-12 13:15:21+00:00</td>\n","      <td>LUTH accident and emergency ward is noting too...</td>\n","      <td>8.6753° N, 9.0810° E, 200km</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2023-04-12 13:15:21+00:00</td>\n","      <td>I was at LUTH emergency one time.There were do...</td>\n","      <td>8.6753° N, 9.0810° E, 200km</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2023-04-07 10:32:19+00:00</td>\n","      <td>@MrLamiofficial @shilepoppa I met a man that c...</td>\n","      <td>8.6753° N, 9.0810° E, 200km</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2023-04-07 10:10:28+00:00</td>\n","      <td>If the dilapidated system is receiving some re...</td>\n","      <td>8.6753° N, 9.0810° E, 200km</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2023-04-07 09:50:33+00:00</td>\n","      <td>@AdesojiMinkail There is nothing real about th...</td>\n","      <td>8.6753° N, 9.0810° E, 200km</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-81d231ad-fe69-4257-8ec8-600b5666d3e6')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-81d231ad-fe69-4257-8ec8-600b5666d3e6 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-81d231ad-fe69-4257-8ec8-600b5666d3e6');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                    Datetime  \\\n","0  2023-04-12 13:15:21+00:00   \n","1  2023-04-12 13:15:21+00:00   \n","2  2023-04-07 10:32:19+00:00   \n","3  2023-04-07 10:10:28+00:00   \n","4  2023-04-07 09:50:33+00:00   \n","\n","                                               tweet  \\\n","0  LUTH accident and emergency ward is noting too...   \n","1  I was at LUTH emergency one time.There were do...   \n","2  @MrLamiofficial @shilepoppa I met a man that c...   \n","3  If the dilapidated system is receiving some re...   \n","4  @AdesojiMinkail There is nothing real about th...   \n","\n","                     Location   \n","0  8.6753° N, 9.0810° E, 200km  \n","1  8.6753° N, 9.0810° E, 200km  \n","2  8.6753° N, 9.0810° E, 200km  \n","3  8.6753° N, 9.0810° E, 200km  \n","4  8.6753° N, 9.0810° E, 200km  "]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["tweets_df.rename(\n","    columns=({ 'Text': 'tweet'}), \n","    inplace=True,\n",")\n","tweets_df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":21,"status":"ok","timestamp":1683940642122,"user":{"displayName":"Boluwatife Morolari","userId":"04350220273514722696"},"user_tz":-60},"id":"9HLCCPVSgvKk","outputId":"761ee19b-ed70-4219-e55b-bc788ef136e9"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-5d0cc5a1-34a8-421b-b88d-ebeebbe2bfdf\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Datetime</th>\n","      <th>tweet</th>\n","      <th>Location</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2023-04-12 13:15:21+00:00</td>\n","      <td>LUTH accident and emergency ward is noting too...</td>\n","      <td>8.6753° N, 9.0810° E, 200km</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2023-04-12 13:15:21+00:00</td>\n","      <td>I was at LUTH emergency one time.There were do...</td>\n","      <td>8.6753° N, 9.0810° E, 200km</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2023-04-07 10:32:19+00:00</td>\n","      <td>@MrLamiofficial @shilepoppa I met a man that c...</td>\n","      <td>8.6753° N, 9.0810° E, 200km</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2023-04-07 10:10:28+00:00</td>\n","      <td>If the dilapidated system is receiving some re...</td>\n","      <td>8.6753° N, 9.0810° E, 200km</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2023-04-07 09:50:33+00:00</td>\n","      <td>@AdesojiMinkail There is nothing real about th...</td>\n","      <td>8.6753° N, 9.0810° E, 200km</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5d0cc5a1-34a8-421b-b88d-ebeebbe2bfdf')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-5d0cc5a1-34a8-421b-b88d-ebeebbe2bfdf button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-5d0cc5a1-34a8-421b-b88d-ebeebbe2bfdf');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                    Datetime  \\\n","0  2023-04-12 13:15:21+00:00   \n","1  2023-04-12 13:15:21+00:00   \n","2  2023-04-07 10:32:19+00:00   \n","3  2023-04-07 10:10:28+00:00   \n","4  2023-04-07 09:50:33+00:00   \n","\n","                                               tweet  \\\n","0  LUTH accident and emergency ward is noting too...   \n","1  I was at LUTH emergency one time.There were do...   \n","2  @MrLamiofficial @shilepoppa I met a man that c...   \n","3  If the dilapidated system is receiving some re...   \n","4  @AdesojiMinkail There is nothing real about th...   \n","\n","                     Location   \n","0  8.6753° N, 9.0810° E, 200km  \n","1  8.6753° N, 9.0810° E, 200km  \n","2  8.6753° N, 9.0810° E, 200km  \n","3  8.6753° N, 9.0810° E, 200km  \n","4  8.6753° N, 9.0810° E, 200km  "]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["tweets_df.head(5)"]},{"cell_type":"markdown","metadata":{"id":"Ge4i9YpS-n9d"},"source":["### **Cleaning and Preprocessing Tweets**\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"T2LyLBFEBkuq"},"outputs":[],"source":["punctuation = '!\"$%&\\'()*+,-./:;<=>?[\\\\]^_`{|}~•@'         # define a string of punctuation symbols\n","\n","# Functions to clean tweets\n","def remove_links(tweet):\n","    \"\"\"Takes a string and removes web links from it\"\"\"\n","    tweet = re.sub(r'http\\S+', '', tweet)   # remove http links\n","    tweet = re.sub(r'bit.ly/\\S+', '', tweet)  # remove bitly links\n","    tweet = tweet.strip('[link]')   # remove [links]\n","    tweet = re.sub(r'pic.twitter\\S+','', tweet)\n","    return tweet\n","\n","def remove_users(tweet):\n","    \"\"\"Takes a string and removes retweet and @user information\"\"\"\n","    tweet = re.sub('(RT\\s@[A-Za-z]+[A-Za-z0-9-_]+)', '', tweet)  # remove re-tweet\n","    tweet = re.sub('(@[A-Za-z]+[A-Za-z0-9-_]+)', '', tweet)  # remove tweeted at\n","    return tweet\n","\n","def remove_hashtags(tweet):\n","    \"\"\"Takes a string and removes any hash tags\"\"\"\n","    tweet = re.sub('(#[A-Za-z]+[A-Za-z0-9-_]+)', '', tweet)  # remove hash tags\n","    return tweet\n","\n","def remove_av(tweet):\n","    \"\"\"Takes a string and removes AUDIO/VIDEO tags or labels\"\"\"\n","    tweet = re.sub('VIDEO:', '', tweet)  # remove 'VIDEO:' from start of tweet\n","    tweet = re.sub('AUDIO:', '', tweet)  # remove 'AUDIO:' from start of tweet\n","    return tweet\n","\n","def tokenize(tweet):\n","    \"\"\"Returns tokenized representation of words in lemma form excluding stopwords\"\"\"\n","    result = []\n","    for token in gensim.utils.simple_preprocess(tweet):\n","        if token not in gensim.parsing.preprocessing.STOPWORDS \\\n","                and len(token) > 2:  # drops words with less than 3 characters\n","            result.append(lemmatize(token))\n","    return result\n","\n","def lemmatize(token):\n","    \"\"\"Returns lemmatization of a token\"\"\"\n","    return WordNetLemmatizer().lemmatize(token, pos='v')\n","\n","def preprocess_tweet(tweet):\n","    \"\"\"Main master function to clean tweets, stripping noisy characters, and tokenizing use lemmatization\"\"\"\n","    tweet = remove_users(tweet)\n","    tweet = remove_links(tweet)\n","    tweet = remove_hashtags(tweet)\n","    tweet = remove_av(tweet)\n","    tweet = tweet.lower()  # lower case\n","    tweet = re.sub('[' + punctuation + ']+', ' ', tweet)  # strip punctuation\n","    tweet = re.sub('\\s+', ' ', tweet)  # remove double spacing\n","    tweet = re.sub('([0-9]+)', '', tweet)  # remove numbers\n","    tweet_token_list = tokenize(tweet)  # apply lemmatization and tokenization\n","    tweet = ' '.join(tweet_token_list)\n","    return tweet\n","\n","def basic_clean(tweet):\n","    \"\"\"Main master function to clean tweets only without tokenization or removal of stopwords\"\"\"\n","    tweet = remove_users(tweet)\n","    tweet = remove_links(tweet)\n","    tweet = remove_hashtags(tweet)\n","    tweet = remove_av(tweet)\n","    tweet = tweet.lower()  # lower case\n","    tweet = re.sub('[' + punctuation + ']+', ' ', tweet)  # strip punctuation\n","    tweet = re.sub('\\s+', ' ', tweet)  # remove double spacing\n","    tweet = re.sub('([0-9]+)', '', tweet)  # remove numbers\n","    tweet = re.sub('📝 …', '', tweet)\n","    return tweet\n","\n","def tokenize_tweets(df):\n","    \"\"\"Main function to read in and return cleaned and preprocessed dataframe.\n","    This can be used in Jupyter notebooks by importing this module and calling the tokenize_tweets() function\n","\n","    Args:\n","        df = data frame object to apply cleaning to\n","\n","    Returns:\n","        pandas data frame with cleaned tokens\n","    \"\"\"\n","\n","    tweets_df['tokens'] = df.tweet.apply(preprocess_tweet)\n","    num_tweets = len(df)\n","    print('Complete. Number of Tweets that have been cleaned and tokenized : {}'.format(num_tweets))\n","    return df"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":354},"executionInfo":{"elapsed":3289,"status":"ok","timestamp":1683940661966,"user":{"displayName":"Boluwatife Morolari","userId":"04350220273514722696"},"user_tz":-60},"id":"e0YF36hpCyy-","outputId":"16b7088a-ccfa-4339-848c-c20da240a58e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Complete. Number of Tweets that have been cleaned and tokenized : 215\n"]},{"data":{"text/html":["\n","  <div id=\"df-df0e1f95-c5de-4294-b0af-e93cfc064f6f\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Datetime</th>\n","      <th>tweet</th>\n","      <th>Location</th>\n","      <th>tokens</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2023-04-12 13:15:21+00:00</td>\n","      <td>LUTH accident and emergency ward is noting too...</td>\n","      <td>8.6753° N, 9.0810° E, 200km</td>\n","      <td>luth accident emergency ward note write home s...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2023-04-12 13:15:21+00:00</td>\n","      <td>I was at LUTH emergency one time.There were do...</td>\n","      <td>8.6753° N, 9.0810° E, 200km</td>\n","      <td>luth emergency time doctor bed want force doct...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2023-04-07 10:32:19+00:00</td>\n","      <td>@MrLamiofficial @shilepoppa I met a man that c...</td>\n","      <td>8.6753° N, 9.0810° E, 200km</td>\n","      <td>meet man come way usa luth radiotherapy servic...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2023-04-07 10:10:28+00:00</td>\n","      <td>If the dilapidated system is receiving some re...</td>\n","      <td>8.6753° N, 9.0810° E, 200km</td>\n","      <td>dilapidate receive repair people come help see...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2023-04-07 09:50:33+00:00</td>\n","      <td>@AdesojiMinkail There is nothing real about th...</td>\n","      <td>8.6753° N, 9.0810° E, 200km</td>\n","      <td>real absolutely government officials spend bil...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-df0e1f95-c5de-4294-b0af-e93cfc064f6f')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-df0e1f95-c5de-4294-b0af-e93cfc064f6f button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-df0e1f95-c5de-4294-b0af-e93cfc064f6f');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                    Datetime  \\\n","0  2023-04-12 13:15:21+00:00   \n","1  2023-04-12 13:15:21+00:00   \n","2  2023-04-07 10:32:19+00:00   \n","3  2023-04-07 10:10:28+00:00   \n","4  2023-04-07 09:50:33+00:00   \n","\n","                                               tweet  \\\n","0  LUTH accident and emergency ward is noting too...   \n","1  I was at LUTH emergency one time.There were do...   \n","2  @MrLamiofficial @shilepoppa I met a man that c...   \n","3  If the dilapidated system is receiving some re...   \n","4  @AdesojiMinkail There is nothing real about th...   \n","\n","                     Location   \\\n","0  8.6753° N, 9.0810° E, 200km   \n","1  8.6753° N, 9.0810° E, 200km   \n","2  8.6753° N, 9.0810° E, 200km   \n","3  8.6753° N, 9.0810° E, 200km   \n","4  8.6753° N, 9.0810° E, 200km   \n","\n","                                              tokens  \n","0  luth accident emergency ward note write home s...  \n","1  luth emergency time doctor bed want force doct...  \n","2  meet man come way usa luth radiotherapy servic...  \n","3  dilapidate receive repair people come help see...  \n","4  real absolutely government officials spend bil...  "]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["tweets_df = tokenize_tweets(tweets_df)\n","tweets_df.head(5)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":337},"executionInfo":{"elapsed":21,"status":"ok","timestamp":1683940661967,"user":{"displayName":"Boluwatife Morolari","userId":"04350220273514722696"},"user_tz":-60},"id":"LG1IOwu2Hp-5","outputId":"4590f19d-1de3-482b-d155-9aa99687e57b"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-dc2e1b52-77ff-46dd-bb42-e785febdf205\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Datetime</th>\n","      <th>tweet</th>\n","      <th>Location</th>\n","      <th>tokens</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2023-04-12 13:15:21+00:00</td>\n","      <td>LUTH accident and emergency ward is noting too...</td>\n","      <td>8.6753° N, 9.0810° E, 200km</td>\n","      <td>luth accident emergency ward note write home s...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2023-04-12 13:15:21+00:00</td>\n","      <td>I was at LUTH emergency one time.There were do...</td>\n","      <td>8.6753° N, 9.0810° E, 200km</td>\n","      <td>luth emergency time doctor bed want force doct...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2023-04-07 10:32:19+00:00</td>\n","      <td>@MrLamiofficial @shilepoppa I met a man that c...</td>\n","      <td>8.6753° N, 9.0810° E, 200km</td>\n","      <td>meet man come way usa luth radiotherapy servic...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2023-04-07 10:10:28+00:00</td>\n","      <td>If the dilapidated system is receiving some re...</td>\n","      <td>8.6753° N, 9.0810° E, 200km</td>\n","      <td>dilapidate receive repair people come help see...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2023-04-07 09:50:33+00:00</td>\n","      <td>@AdesojiMinkail There is nothing real about th...</td>\n","      <td>8.6753° N, 9.0810° E, 200km</td>\n","      <td>real absolutely government officials spend bil...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dc2e1b52-77ff-46dd-bb42-e785febdf205')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-dc2e1b52-77ff-46dd-bb42-e785febdf205 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-dc2e1b52-77ff-46dd-bb42-e785febdf205');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                    Datetime  \\\n","0  2023-04-12 13:15:21+00:00   \n","1  2023-04-12 13:15:21+00:00   \n","2  2023-04-07 10:32:19+00:00   \n","3  2023-04-07 10:10:28+00:00   \n","4  2023-04-07 09:50:33+00:00   \n","\n","                                               tweet  \\\n","0  LUTH accident and emergency ward is noting too...   \n","1  I was at LUTH emergency one time.There were do...   \n","2  @MrLamiofficial @shilepoppa I met a man that c...   \n","3  If the dilapidated system is receiving some re...   \n","4  @AdesojiMinkail There is nothing real about th...   \n","\n","                     Location   \\\n","0  8.6753° N, 9.0810° E, 200km   \n","1  8.6753° N, 9.0810° E, 200km   \n","2  8.6753° N, 9.0810° E, 200km   \n","3  8.6753° N, 9.0810° E, 200km   \n","4  8.6753° N, 9.0810° E, 200km   \n","\n","                                              tokens  \n","0  luth accident emergency ward note write home s...  \n","1  luth emergency time doctor bed want force doct...  \n","2  meet man come way usa luth radiotherapy servic...  \n","3  dilapidate receive repair people come help see...  \n","4  real absolutely government officials spend bil...  "]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["tweets_df.to_csv('preprocessed_tweets', index=False)\n","tweets_df.head()"]},{"cell_type":"markdown","metadata":{"id":"2dYkeqnoXv6n"},"source":["### **GSD TEST**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8nCGHDIkpM9h"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","%cd /content/drive/My\\ Drive/Project"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":882,"status":"ok","timestamp":1683940782968,"user":{"displayName":"Boluwatife Morolari","userId":"04350220273514722696"},"user_tz":-60},"id":"0qHTWZfIUxaK","outputId":"2d80272f-1714-44d1-c6bc-0c157c4b1e9f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Overwriting mylib.py\n"]}],"source":["%%writefile mylib.py\n","\n","from numpy.random import multinomial\n","from numpy import log, exp\n","from numpy import argmax\n","import json\n","\n","class MovieGroupProcess:\n","    def __init__(self, K=8, alpha=0.1, beta=0.1, n_iters=30):\n","        '''\n","        A MovieGroupProcess is a conceptual model introduced by Yin and Wang 2014 to\n","        describe their Gibbs sampling algorithm for a Dirichlet Mixture Model for the\n","        clustering short text documents.\n","        Reference: http://dbgroup.cs.tsinghua.edu.cn/wangjy/papers/KDD14-GSDMM.pdf\n","\n","        Imagine a professor is leading a film class. At the start of the class, the students\n","        are randomly assigned to K tables. Before class begins, the students make lists of\n","        their favorite films. The teacher reads the role n_iters times. When\n","        a student is called, the student must select a new table satisfying either:\n","            1) The new table has more students than the current table.\n","        OR\n","            2) The new table has students with similar lists of favorite movies.\n","\n","        :param K: int\n","            Upper bound on the number of possible clusters. Typically many fewer\n","        :param alpha: float between 0 and 1\n","            Alpha controls the probability that a student will join a table that is currently empty\n","            When alpha is 0, no one will join an empty table.\n","        :param beta: float between 0 and 1\n","            Beta controls the student's affinity for other students with similar interests. A low beta means\n","            that students desire to sit with students of similar interests. A high beta means they are less\n","            concerned with affinity and are more influenced by the popularity of a table\n","        :param n_iters:\n","        '''\n","        self.K = K\n","        self.alpha = alpha\n","        self.beta = beta\n","        self.n_iters = n_iters\n","\n","        # slots for computed variables\n","        self.number_docs = None\n","        self.vocab_size = None\n","        self.cluster_doc_count = [0 for _ in range(K)]\n","        self.cluster_word_count = [0 for _ in range(K)]\n","        self.cluster_word_distribution = [{} for i in range(K)]\n","\n","    @staticmethod\n","    def from_data(K, alpha, beta, D, vocab_size, cluster_doc_count, cluster_word_count, cluster_word_distribution):\n","        '''\n","        Reconstitute a MovieGroupProcess from previously fit data\n","        :param K:\n","        :param alpha:\n","        :param beta:\n","        :param D:\n","        :param vocab_size:\n","        :param cluster_doc_count:\n","        :param cluster_word_count:\n","        :param cluster_word_distribution:\n","        :return:\n","        '''\n","        mgp = MovieGroupProcess(K, alpha, beta, n_iters=30)\n","        mgp.number_docs = D\n","        mgp.vocab_size = vocab_size\n","        mgp.cluster_doc_count = cluster_doc_count\n","        mgp.cluster_word_count = cluster_word_count\n","        mgp.cluster_word_distribution = cluster_word_distribution\n","        return mgp\n","\n","    @staticmethod\n","    def _sample(p):\n","        '''\n","        Sample with probability vector p from a multinomial distribution\n","        :param p: list\n","            List of probabilities representing probability vector for the multinomial distribution\n","        :return: int\n","            index of randomly selected output\n","        '''\n","        return [i for i, entry in enumerate(multinomial(1, p)) if entry != 0][0]\n","\n","    def fit(self, docs, vocab_size):\n","        '''\n","        Cluster the input documents\n","        :param docs: list of list\n","            list of lists containing the unique token set of each document\n","        :param V: total vocabulary size for each document\n","        :return: list of length len(doc)\n","            cluster label for each document\n","        '''\n","        alpha, beta, K, n_iters, V = self.alpha, self.beta, self.K, self.n_iters, vocab_size\n","\n","        D = len(docs)\n","        self.number_docs = D\n","        self.vocab_size = vocab_size\n","\n","        # unpack to easy var names\n","        m_z, n_z, n_z_w = self.cluster_doc_count, self.cluster_word_count, self.cluster_word_distribution\n","        cluster_count = K\n","        d_z = [None for i in range(len(docs))]\n","\n","        # initialize the clusters\n","        for i, doc in enumerate(docs):\n","\n","            # choose a random  initial cluster for the doc\n","            z = self._sample([1.0 / K for _ in range(K)])\n","            d_z[i] = z\n","            m_z[z] += 1\n","            n_z[z] += len(doc)\n","\n","            for word in doc:\n","                if word not in n_z_w[z]:\n","                    n_z_w[z][word] = 0\n","                n_z_w[z][word] += 1\n","\n","        for _iter in range(n_iters):\n","            total_transfers = 0\n","\n","            for i, doc in enumerate(docs):\n","\n","                # remove the doc from it's current cluster\n","                z_old = d_z[i]\n","\n","                m_z[z_old] -= 1\n","                n_z[z_old] -= len(doc)\n","\n","                for word in doc:\n","                    n_z_w[z_old][word] -= 1\n","\n","                    # compact dictionary to save space\n","                    if n_z_w[z_old][word] == 0:\n","                        del n_z_w[z_old][word]\n","\n","                # draw sample from distribution to find new cluster\n","                p = self.score(doc)\n","                z_new = self._sample(p)\n","\n","                # transfer doc to the new cluster\n","                if z_new != z_old:\n","                    total_transfers += 1\n","\n","                d_z[i] = z_new\n","                m_z[z_new] += 1\n","                n_z[z_new] += len(doc)\n","\n","                for word in doc:\n","                    if word not in n_z_w[z_new]:\n","                        n_z_w[z_new][word] = 0\n","                    n_z_w[z_new][word] += 1\n","\n","            cluster_count_new = sum([1 for v in m_z if v > 0])\n","            print(\"In stage %d: transferred %d clusters with %d clusters populated\" % (\n","            _iter, total_transfers, cluster_count_new))\n","            if total_transfers == 0 and cluster_count_new == cluster_count and _iter>25:\n","                print(\"Converged.  Breaking out.\")\n","                break\n","            cluster_count = cluster_count_new\n","        self.cluster_word_distribution = n_z_w\n","        return d_z\n","\n","    def score(self, doc):\n","        '''\n","        Score a document\n","\n","        Implements formula (3) of Yin and Wang 2014.\n","        http://dbgroup.cs.tsinghua.edu.cn/wangjy/papers/KDD14-GSDMM.pdf\n","\n","        :param doc: list[str]: The doc token stream\n","        :return: list[float]: A length K probability vector where each component represents\n","                              the probability of the document appearing in a particular cluster\n","        '''\n","        alpha, beta, K, V, D = self.alpha, self.beta, self.K, self.vocab_size, self.number_docs\n","        m_z, n_z, n_z_w = self.cluster_doc_count, self.cluster_word_count, self.cluster_word_distribution\n","\n","        p = [0 for _ in range(K)]\n","\n","        #  We break the formula into the following pieces\n","        #  p = N1*N2/(D1*D2) = exp(lN1 - lD1 + lN2 - lD2)\n","        #  lN1 = log(m_z[z] + alpha)\n","        #  lN2 = log(D - 1 + K*alpha)\n","        #  lN2 = log(product(n_z_w[w] + beta)) = sum(log(n_z_w[w] + beta))\n","        #  lD2 = log(product(n_z[d] + V*beta + i -1)) = sum(log(n_z[d] + V*beta + i -1))\n","\n","        lD1 = log(D - 1 + K * alpha)\n","        doc_size = len(doc)\n","        for label in range(K):\n","            lN1 = log(m_z[label] + alpha)\n","            lN2 = 0\n","            lD2 = 0\n","            for word in doc:\n","                lN2 += log(n_z_w[label].get(word, 0) + beta)\n","            for j in range(1, doc_size +1):\n","                lD2 += log(n_z[label] + V * beta + j - 1)\n","            p[label] = exp(lN1 - lD1 + lN2 - lD2)\n","\n","        # normalize the probability vector\n","        pnorm = sum(p)\n","        pnorm = pnorm if pnorm>0 else 1\n","        return [pp/pnorm for pp in p]\n","\n","    def choose_best_label(self, doc):\n","        '''\n","        Choose the highest probability label for the input document\n","        :param doc: list[str]: The doc token stream\n","        :return:\n","        '''\n","        p = self.score(doc)\n","        return argmax(p),max(p)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":793,"status":"ok","timestamp":1683599709460,"user":{"displayName":"Boluwatife Morolari","userId":"04350220273514722696"},"user_tz":-60},"id":"mQ0m4ZYRXMX1","outputId":"05a86a66-3a83-4cdc-832c-47b425120fcb"},"outputs":[{"name":"stdout","output_type":"stream","text":["-rw------- 1 root root 7819 May  9 02:34 mylib.py\n"]}],"source":["!ls -l mylib.py"]},{"cell_type":"markdown","metadata":{"id":"WaN7spayJAsz"},"source":["### **TOPIC MODELLING WITH STTM(Short text topic modelling) USING GSDMM(Gibbs Samplign Dirichlet Mixture Model)**"]},{"cell_type":"markdown","metadata":{"id":"RwtVW5lLKAIV"},"source":["STTM Implementation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sTGJylB6KCsX"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import pickle\n","import mylib\n","from mylib import MovieGroupProcess\n","from tqdm import tqdm"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"M84qQo-SYcz3"},"outputs":[],"source":["# convert string of tokens into tokens list\n","tweets_df['tokens']= tweets_df['tokens'].apply(str)\n","tweets_df['tokens'] = tweets_df.tokens.apply(lambda x: re.split('\\s', x))\n","tweets_df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xl2JOm6LY2jo"},"outputs":[],"source":["# create a single list of tweet tokens\n","docs = tweets_df['tokens'].tolist()\n","docs[:3]  # view top 3 elements"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2kqFnnPRY827"},"outputs":[],"source":["%%time\n","# Train STTM model\n","#    K = number of potential topics\n","#    alpha = controls completeness\n","#    beta =  controls homogeneity \n","#    n_iters = number of iterations\n","mgp = mylib.MovieGroupProcess(K=10, alpha=0.1, beta=0.5, n_iters=30)\n","vocab = set(x for doc in docs for x in doc)\n","n_terms = len(vocab)\n","y = mgp.fit(docs, n_terms)\n","\n","# Save model\n","with open('/content/10clusters.model', 'wb') as f:\n","    pickle.dump(mgp, f)\n","    f.close()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0JzRksW-g0BJ"},"outputs":[],"source":["# load in trained model \n","filehandler = open('/content/10clusters.model', 'rb')\n","mgp = pickle.load(filehandler)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZbPUaJgfg5vk"},"outputs":[],"source":["# define helper functions\n","def top_words(cluster_word_distribution, top_cluster, values):\n","    '''prints the top words in each cluster'''\n","    for cluster in top_cluster:\n","        sort_dicts =sorted(mgp.cluster_word_distribution[cluster].items(), key=lambda k: k[1], reverse=True)[:values]\n","        print('Cluster %s : %s'%(cluster,sort_dicts))\n","        print(' — — — — — — — — —')\n","        \n","def cluster_importance(mgp):\n","    '''returns a word-topic matrix[phi] where each value represents\n","    the word importance for that particular cluster;\n","    phi[i][w] would be the importance of word w in topic i.\n","    '''\n","    n_z_w = mgp.cluster_word_distribution\n","    beta, V, K = mgp.beta, mgp.vocab_size, mgp.K\n","    phi = [{} for i in range(K)]\n","    for z in range(K):\n","        for w in n_z_w[z]:\n","            phi[z][w] = (n_z_w[z][w]+beta)/(sum(n_z_w[z].values())+V*beta)\n","    return phi\n","\n","def topic_allocation(df, docs, mgp, topic_dict):\n","    '''allocates all topics to each document in original dataframe,\n","    adding two columns for cluster number and cluster description'''\n","    topic_allocations = []\n","    for doc in tqdm(docs):\n","        topic_label, score = mgp.choose_best_label(doc)\n","        topic_allocations.append(topic_label)\n","\n","    df['cluster'] = topic_allocations\n","\n","    df['topic_name'] = df.cluster.apply(lambda x: get_topic_name(x, topic_dict))\n","    print('Complete. Number of documents with topic allocated: {}'.format(len(df)))\n","\n","def get_topic_name(doc, topic_dict):\n","    '''returns the topic name string value from a dictionary of topics'''\n","    topic_desc = topic_dict[doc]\n","    return topic_desc"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"z8coxD6Tg8cv"},"outputs":[],"source":["doc_count = np.array(mgp.cluster_doc_count)\n","print('Number of documents per topic :', doc_count)\n","print('*'*20)\n","\n","# topics sorted by the number of documents they are allocated to\n","top_index = doc_count.argsort()[-10:][::-1]\n","print('Most important clusters (by number of docs inside):', top_index)\n","print('*'*20)\n","\n","# show the top 5 words in term frequency for each cluster \n","topic_indices = np.arange(start=0, stop=len(doc_count), step=1)\n","top_words(mgp.cluster_word_distribution, topic_indices, 5)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JnH7NTkzhSGd"},"outputs":[],"source":["# define dictionary topics in same sequential order\n","# as resulting clusters from gsdmm model \n","topic_dict = {}\n","topic_names = ['Hospital facilities and services',\n","               'Medical professionals and patient outcomes',\n","               'Hospital bed space and patient capacity',\n","               'General health concerns and issues',\n","               'Miscellaneous comments and inquiries',\n","               'Assistance and emergency services',\n","               '',\n","               '',\n","               'Hospital staff and equipment',\n","               'High mortality rates due to inadequate healthcare services']\n","\n","for i, topic_num in enumerate(topic_indices):\n","    topic_dict[topic_num]=topic_names[i]\n","    \n","# allocate topics to original data frame \n","topic_allocation(tweets_df, docs, mgp, topic_dict)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cu0a5RUajjE2"},"outputs":[],"source":["tweets_df[['tweet', 'tokens', 'cluster', 'topic_name']].sample(5)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XdaCb8mwjsXq"},"outputs":[],"source":["# save model results to csv\n","tweets_df.to_csv(r'/content/drive/MyDrive/Project/sttm_10topics_results.csv', index = False,  \n","                 header=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ER7cuj70lS-R"},"outputs":[],"source":["!pip install plotly"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5FoLVZdUl2mQ"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import plotly.graph_objects as go\n","import plotly.express as px\n"," \n","tweets_df = pd.read_csv(r'/content/drive/MyDrive/Project/sttm_10topics_results.csv')\n","tweets_df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qjj4QylkmI-s"},"outputs":[],"source":["# create data frame of unique cluster/topic names only\n","topics_df = tweets_df[['cluster', 'topic_name']].drop_duplicates().sort_values(by='cluster')\n","topics_df.reset_index(inplace=True, drop=True)\n","topics_df"]},{"cell_type":"markdown","metadata":{"id":"Yv_YTlNIpblv"},"source":["### **LDA**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1280,"status":"ok","timestamp":1683606284976,"user":{"displayName":"Boluwatife Morolari","userId":"04350220273514722696"},"user_tz":-60},"id":"LHaqdYgMs0jM","outputId":"91bbb28d-e356-4544-bb8e-277efa4ac2a5"},"outputs":[{"name":"stderr","output_type":"stream","text":["WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n"]},{"name":"stdout","output_type":"stream","text":["Topic 0: 0.023*\"luth\" + 0.020*\"hospital\" + 0.013*\"doctor\" + 0.008*\"teach\" + 0.006*\"come\" + 0.006*\"bed\" + 0.006*\"people\" + 0.006*\"upth\" + 0.006*\"medical\" + 0.005*\"emergency\"\n","Topic 1: 0.030*\"luth\" + 0.016*\"hospital\" + 0.010*\"die\" + 0.009*\"bed\" + 0.007*\"uch\" + 0.006*\"know\" + 0.006*\"work\" + 0.005*\"upth\" + 0.005*\"nigeria\" + 0.004*\"space\"\n"]}],"source":["import pandas as pd\n","import gensim\n","from gensim import corpora\n","\n","# Load the CSV file into a pandas DataFrame\n","data_dir = '/content/preprocessed_tweets'\n","data_df = pd.read_csv(data_dir)\n","\n","# Extract the text column from the DataFrame\n","texts = data_df['tokens'].tolist()\n","\n","# Tokenize the texts and create a dictionary\n","tokenized_texts = [text.split() for text in texts]\n","dictionary = corpora.Dictionary(tokenized_texts)\n","\n","# Convert the tokenized texts into a bag-of-words representation\n","corpus = [dictionary.doc2bow(text) for text in tokenized_texts]\n","\n","# Train the LDA model\n","num_topics = 2\n","lda_model = gensim.models.LdaModel(corpus, num_topics=num_topics, id2word=dictionary)\n","\n","# Get the topic distribution for each document\n","topic_dists = lda_model.get_document_topics(corpus)\n","\n","# Extract the dominant topic for each document\n","dominant_topics = [max(topic_dist, key=lambda x: x[1])[0] for topic_dist in topic_dists]\n","\n","# Add the dominant topic to the DataFrame\n","data_df['dominant_topic'] = dominant_topics\n","\n","# Save the updated DataFrame to a new CSV file\n","output_dir = '/content/drive/MyDrive/output.csv'\n","data_df.to_csv(output_dir, index=False)\n","\n","# Print the topics and their corresponding words\n","for topic_id in range(num_topics):\n","    print(f\"Topic {topic_id}: {lda_model.print_topic(topic_id)}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vcNZhS1gsWaD"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"yzj2PP7eloNK"},"source":["### **Sentimnet Analysis**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nq6ux-T3irTD"},"outputs":[],"source":[" #Load the CSV file into a pandas DataFrame\n","tweets_df = '/content/drive/MyDrive/Project/sttm_10topics_results.csv'\n","tweets_df = pd.read_csv(tweets_df)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TZicuM8ilkLy"},"outputs":[],"source":["from nltk.corpus import stopwords\n","nltk.download('stopwords')\n","\n","\n","def preprocess_text2(text):\n","  sentence = text.lower()\n","# Remove multiple spaces\n","  sentence = re.sub(r'\\s+', ' ', sentence)  # Next, we remove all the single characters and replace it by a space which creates multiple spaces in our text. Finally, we remove the multiple spaces from our text as well.\n","\n","   # Remove Stopwords\n","  pattern = re.compile(r'\\b(' + r'|'.join(stopwords.words('english')) + r')\\b\\s*')\n","  sentence = pattern.sub('', sentence)\n","\n","  return sentence"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eKW6zH8Fmgwo"},"outputs":[],"source":["tweets_df['tweetStop'] = tweets_df.tweet.apply(preprocess_text2)  "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3GJRzHKOmDwI"},"outputs":[],"source":["tweets_df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_pdHKa2Ucjnf"},"outputs":[],"source":["from textblob import TextBlob\n","\n","#creating function for subjectivity\n","def getsubjectivity(text):\n","  return TextBlob(text).sentiment.subjectivity\n","  \n","#creating function for polarity\n","def getpolarity(text):\n","  return TextBlob(text).sentiment.polarity\n","\n","#creating new columns for the sujectivity and polarity\n","tweets_df[\"Subjectivity\"] = tweets_df[\"tweetStop\"].apply(getsubjectivity)\n","tweets_df[\"Polarity\"] = tweets_df[\"tweetStop\"].apply(getpolarity)\n","\n","#viewing the new dataframe\n","tweets_df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NhnM4Akbh3IB"},"outputs":[],"source":["#create a wordcloud to view the most used words in the clean tweets\n","from wordcloud import WordCloud\n","\n","all_words = ' '.join([text for text in tweets_df['tokens']])\n","wordcloud = WordCloud(width=500, height=300, random_state=21, max_font_size=119).generate(all_words)\n","\n","plt.figure( figsize=(20,10) )\n","plt.imshow(wordcloud)\n","plt.axis(\"off\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"k8pqjXRbiMNB"},"outputs":[],"source":["#creating a fubnction to compute the tweet classification\n","\n","def classification(score):\n","  if score <0:\n","    return \"Dissatisfied\"\n","  elif score == 0:\n","    return \"Nuetral\"\n","  else:\n","    return \"Not Dissatisfied\"\n","\n","tweets_df[\"Classification\"]  = tweets_df[\"Polarity\"].apply(classification)\n","\n","tweets_df"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1684287712085,"user":{"displayName":"Boluwatife Morolari","userId":"04350220273514722696"},"user_tz":-60},"id":"Ylfx311_kLHK","outputId":"2a57d36f-e5aa-469f-d69c-d13671fa2a1a"},"outputs":[{"data":{"text/plain":["(78, 10)"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["#getting the list of those that are Not dissatisfied\n","tweets_df[tweets_df[\"Classification\"] == \"Not Dissatisfied\"].shape"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":385,"status":"ok","timestamp":1684287710164,"user":{"displayName":"Boluwatife Morolari","userId":"04350220273514722696"},"user_tz":-60},"id":"RZ6zM1vhkU-z","outputId":"461cbb0e-d8df-4a34-df4c-317c9e85cffa"},"outputs":[{"data":{"text/plain":["(74, 10)"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["#getting the list of those that are dissatiafied\n","tweets_df[tweets_df[\"Classification\"] == \"Dissatisfied\"].shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"otCkIBvWdYgJ"},"outputs":[],"source":["tweets_df.head()\n","tweets_df.to_csv('Output.csv', index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1661,"status":"ok","timestamp":1685045931580,"user":{"displayName":"Boluwatife Morolari","userId":"04350220273514722696"},"user_tz":-60},"id":"WwYLdFGLkF0-","outputId":"c3f7641a-f3dd-49d5-802a-3c209099b599"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"]},{"data":{"text/plain":["True"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["import nltk\n","nltk.download('vader_lexicon')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tHYrI6kZj5dS"},"outputs":[],"source":["import nltk\n","import csv\n","from nltk.sentiment import SentimentIntensityAnalyzer\n","\n","def analyze_sentiment(text):\n","    if text is None:\n","        return 'N/A', {'compound': 0.0, 'pos': 0.0, 'neu': 0.0, 'neg': 0.0}\n","    \n","    sia = SentimentIntensityAnalyzer()\n","    sentiment_scores = sia.polarity_scores(text)\n","    compound_score = sentiment_scores['compound']\n","    \n","    if compound_score > 0:\n","        sentiment_label = 'Positive'\n","    elif compound_score < 0:\n","        sentiment_label = 'Negative'\n","    else:\n","        sentiment_label = 'Neutral'\n","    \n","    return sentiment_label, sentiment_scores\n","\n","def process_csv(input_file, text_column, output_file):\n","    with open(input_file, 'r') as csv_file:\n","        reader = csv.DictReader(csv_file)\n","        fieldnames = reader.fieldnames + ['SentimentLabel', 'SentimentScores']\n","        \n","        with open(output_file, 'w', newline='') as output_csv:\n","            writer = csv.DictWriter(output_csv, fieldnames=fieldnames)\n","            writer.writeheader()\n","            \n","            for row in reader:\n","                text = row[text_column]\n","                sentiment_label, sentiment_scores = analyze_sentiment(text)\n","                row['SentimentLabel'] = sentiment_label\n","                row['SentimentScores'] = sentiment_scores\n","                writer.writerow(row)\n","\n","# Example usage\n","input_file = '/content/drive/MyDrive/finalOutput12.csv'\n","text_column = 'tweetStop'\n","output_file = '/content/drive/MyDrive/finalOutput12.csv'\n","\n","process_csv(input_file, text_column, output_file)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Cd81IiAImxZh"},"outputs":[],"source":[" #Load the CSV file into a pandas DataFrame\n","tweets_df2 = '/content/drive/MyDrive/finalOutput12.csv'\n","tweets_df2 = pd.read_csv(tweets_df2)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"awQlAU1bmzr7"},"outputs":[],"source":["tweets_df2.head()"]},{"cell_type":"markdown","metadata":{"id":"nCchXzVwdZ39"},"source":["### **Visualization**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0indNf9skMMn"},"outputs":[],"source":[" #Load the CSV file into a pandas DataFrame\n","tweets_df2 = '/content/drive/MyDrive/finalOutput12.csv'\n","tweets_df2 = pd.read_csv(tweets_df2)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OsDySZeInpKH"},"outputs":[],"source":["tweets_df2.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EmfF3hOrlccU"},"outputs":[],"source":["import pandas as pd\n","\n","def drop_column(input_file, column_name):\n","    df = pd.read_csv(input_file)\n","    df.drop(column_name, axis=1, inplace=True)\n","    df.to_csv(input_file, index=False)\n","\n","# Example usage\n","input_file = '/content/drive/MyDrive/finalOutput12.csv'\n","column_name = 'Classification'\n","\n","drop_column(input_file, column_name)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kIY3H1yQJMgh"},"outputs":[],"source":["tweets_df2.head()"]},{"cell_type":"markdown","metadata":{"id":"62EDdOOiEwsT"},"source":["### **Getting the lat and lng**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vjjMBI1ANvkP"},"outputs":[],"source":[" #Load the CSV file into a pandas DataFrame\n","tweets_df2 = '/content/drive/MyDrive/finalOutput12.csv'\n","tweets_df2 = pd.read_csv(tweets_df2)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"piB97fzM2qXd"},"outputs":[],"source":["import csv\n","\n","def replace_luth_with_full_name(file_path, column_index):\n","    with open(file_path, 'r', newline='') as csvfile:\n","        reader = csv.reader(csvfile)\n","        rows = list(reader)\n","        \n","    for row in rows:\n","        if column_index < len(row):\n","            row[column_index] = row[column_index].replace('University College Hospital', '🇳🇬 University College Hospital (UCH)')\n","    \n","    with open(file_path, 'w', newline='') as csvfile:\n","        writer = csv.writer(csvfile)\n","        writer.writerows(rows)\n","\n","# Example usage\n","replace_luth_with_full_name('/content/drive/MyDrive/finalOutput12.csv', 9)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":118776,"status":"ok","timestamp":1685359851497,"user":{"displayName":"Boluwatife Morolari","userId":"04350220273514722696"},"user_tz":-60},"id":"LqFsMWVr0NRL","outputId":"23322ee8-22bb-4774-886d-16958378038f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Updated CSV file saved to: /content/drive/MyDrive/bolu.csv\n"]}],"source":["import csv\n","import requests\n","import pandas as pd\n","\n","# OpenCage Geocoding API credentials\n","API_KEY = 'e25ef35f52094bbd96273fdccd4dcc1a'\n","\n","# CSV file path\n","csv_file = '/content/drive/MyDrive/finalOutput12.csv'\n","\n","# Column index containing hospital names (starting from 0)\n","hospital_name_column = 9\n","\n","# Function to geocode hospital names\n","def geocode_hospitals(csv_file, hospital_name_column):\n","    # Open the CSV file and create a DataFrame\n","    data = pd.read_csv(csv_file)\n","\n","    # Create new columns for latitude and longitude\n","    data['Latitude'] = None\n","    data['Longitude'] = None\n","\n","    # Iterate over the rows\n","    for index, row in data.iterrows():\n","        hospital_name = row[hospital_name_column]\n","\n","        # Geocode the hospital name using OpenCage API\n","        response = requests.get(f'https://api.opencagedata.com/geocode/v1/json?q={hospital_name}&key={API_KEY}')\n","\n","        # Parse the response\n","        result = response.json()\n","        if 'results' in result and len(result['results']) > 0:\n","            first_result = result['results'][0]\n","            latitude = first_result['geometry']['lat']\n","            longitude = first_result['geometry']['lng']\n","            country = first_result['components'].get('country')\n","\n","            if country == 'Nigeria':\n","                # Update latitude and longitude columns in the DataFrame\n","                data.at[index, 'Latitude'] = latitude\n","                data.at[index, 'Longitude'] = longitude\n","            else:\n","                print(f'Geocoding result outside Nigeria for hospital: {hospital_name}')\n","        else:\n","            print(f'Geocoding failed for hospital: {hospital_name}')\n","\n","    # Save the updated DataFrame with latitude and longitude to a new CSV file\n","    updated_csv_file = '/content/drive/MyDrive/bolu.csv'\n","    data.to_csv(updated_csv_file, index=False)\n","    print(f'Updated CSV file saved to: {updated_csv_file}')\n","\n","# Call the function to geocode hospitals and update the DataFrame\n","geocode_hospitals(csv_file, hospital_name_column)\n"]},{"cell_type":"markdown","metadata":{"id":"wRUEeJgjE5h3"},"source":["### **visualization Continues**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"25gCySoDdcg7"},"outputs":[],"source":["import pandas as pd\n","import re\n","\n","# Regular expression pattern to extract latitude and longitude\n","pattern = r'([0-9.]+)°\\s*([NS]),\\s*([0-9.]+)°\\s*([WE])'\n","\n","# Function to extract latitude and longitude from the location string\n","def extract_coordinates(location_string):\n","    matches = re.findall(pattern, location_string)\n","    if matches:\n","        latitude = float(matches[0][0])\n","        if matches[0][1] == 'S':\n","            latitude *= -1  # Convert to negative if southern hemisphere\n","\n","        longitude = float(matches[0][2])\n","        if matches[0][3] == 'W':\n","            longitude *= -1  # Convert to negative if western hemisphere\n","\n","        return latitude, longitude\n","    else:\n","        return None, None\n","\n","# Apply the extract_coordinates function to the 'Location' column and create new 'Latitude' and 'Longitude' columns\n","tweets_df['Latitude'], tweets_df['Longitude'] = zip(*tweets_df['Location '].map(extract_coordinates))\n","\n","# Save the modified DataFrame to a new CSV file\n","tweets_df.to_csv('/content/drive/MyDrive/bolu.csv', index=False)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NOQ4RwGSFafl"},"outputs":[],"source":["tweets_df.head()"]},{"cell_type":"markdown","metadata":{"id":"CLMarWfiHNbk"},"source":["### **Main Part**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"VN2iqvplsZLG","outputId":"d689d9e0-38ff-4e47-d249-19b662625664"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting geopandas\n","  Downloading geopandas-0.13.0-py3-none-any.whl (1.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting fiona>=1.8.19 (from geopandas)\n","  Downloading Fiona-1.9.4.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m41.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from geopandas) (23.1)\n","Requirement already satisfied: pandas>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from geopandas) (1.5.3)\n","Collecting pyproj>=3.0.1 (from geopandas)\n","  Downloading pyproj-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m71.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: shapely>=1.7.1 in /usr/local/lib/python3.10/dist-packages (from geopandas) (2.0.1)\n","Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.10/dist-packages (from fiona>=1.8.19->geopandas) (23.1.0)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from fiona>=1.8.19->geopandas) (2022.12.7)\n","Requirement already satisfied: click~=8.0 in /usr/local/lib/python3.10/dist-packages (from fiona>=1.8.19->geopandas) (8.1.3)\n","Collecting click-plugins>=1.0 (from fiona>=1.8.19->geopandas)\n","  Downloading click_plugins-1.1.1-py2.py3-none-any.whl (7.5 kB)\n","Collecting cligj>=0.5 (from fiona>=1.8.19->geopandas)\n","  Downloading cligj-0.7.2-py3-none-any.whl (7.1 kB)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from fiona>=1.8.19->geopandas) (1.16.0)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.0->geopandas) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.0->geopandas) (2022.7.1)\n","Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.0->geopandas) (1.22.4)\n","Installing collected packages: pyproj, cligj, click-plugins, fiona, geopandas\n","Successfully installed click-plugins-1.1.1 cligj-0.7.2 fiona-1.9.4.post1 geopandas-0.13.0 pyproj-3.5.0\n"]}],"source":["!pip install geopandas"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fvlOCXXTsI9q"},"outputs":[],"source":["import pandas as pd\n","import geopandas as gpd\n","from geopy.geocoders import Nominatim\n","import matplotlib.pyplot as plt\n","\n","# Load the collected data into a pandas DataFrame\n","df = pd.read_csv('/content/drive/MyDrive/tweets_with_coordinates.csv')\n","\n","# Example: Plotting sentiment on a map using geopandas and matplotlib\n","geolocator = Nominatim(user_agent='geoanalysis')\n","\n","# Create a GeoDataFrame from the DataFrame\n","gdf = gpd.GeoDataFrame(df, geometry=gpd.points_from_xy(df.Longitude, df.Latitude))\n","\n","# Plot sentiment on a map\n","fig, ax = plt.subplots(figsize=(12, 8))\n","gdf.plot(ax=ax, column='Classification', cmap='RdYlGn', legend=True)\n","ax.set_title('Classification Analysis of Hospital Tweets in Nigeria')\n","plt.show()\n","\n","#Preprocess sentimnet values\n","sentimnet_mapping = {\n","    'Dissatisfied': -1,\n","    'Not Dissatisfied': 1,\n","    'Nuetral': 0\n","}\n","\n","df['Sentiment'] = df['Classification'].map(sentimnet_mapping)\n","\n","# Example: Calculate statistics\n","average_sentiment = df['Sentiment'].mean()\n","positive_tweets = df[df['Sentiment'] > 0]\n","negative_tweets = df[df['Sentiment'] < 0]\n","total_tweets = len(df)\n","\n","# Example: Generate a report or presentation based on the findings\n","report = f\"\"\"\n","Sentiment Analysis Report:\n","--------------------------\n","- Average Sentiment: {average_sentiment}\n","- Total Tweets: {total_tweets}\n","- Positive Tweets: {len(positive_tweets)}\n","- Negative Tweets: {len(negative_tweets)}\n","\"\"\"\n","\n","# Additional Analyses\n","\n","\n","\n","print(report)\n","# You can save the report to a file or use it to generate a presentation."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4IRySbFzzWw2"},"outputs":[],"source":["import os\n","import geopandas as gpd\n","\n","os.environ['SHAPE_RESTORE_SHX'] = 'YES'\n","bdr1 = gpd.read_file('/content/drive/MyDrive/nga_polbnda_adm0_1m.shp')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fTpROrD3vZYg"},"outputs":[],"source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","# Read the CSV file containing latitude and longitude data\n","data = pd.read_csv('/content/drive/MyDrive/finalOutput12.csv')\n","\n","# Extract latitude and longitude columns from the DataFrame\n","latitude = data['Latitude']\n","longitude = data['Longitude']\n","\n","# Read the boundary data using GeoPandas\n","bdr1 = gpd.read_file('/content/drive/MyDrive/nga_polbnda_adm0_1m.shp')\n","\n","# Create the plot\n","fig, ax = plt.subplots(figsize=(10, 10))\n","bdr1.plot(ax=ax, edgecolor='black', color='white')\n","ax.scatter(x=longitude, y=latitude, c='red', s=10, alpha=0.3)\n","plt.grid()\n","plt.show()\n"]}],"metadata":{"colab":{"collapsed_sections":["TDIXewieoj03","Ji8UEayMx7rA","U99DUKztzYgK","vPZ8nwBoO2p2","9dhSFnOo9sDQ","Ge4i9YpS-n9d","2dYkeqnoXv6n","WaN7spayJAsz","Yv_YTlNIpblv","yzj2PP7eloNK","CLMarWfiHNbk"],"provenance":[],"mount_file_id":"1fXNZlqq8PzdxCeh0MMAUboQIvn9k7gJL","authorship_tag":"ABX9TyPOKYhHgPR9fzHQ73fXNh0B"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}